{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T18:02:57.239096Z",
     "start_time": "2020-02-19T18:02:56.023838Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import os\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import bar\n",
    "# from tqdm.notebook import tqdm as tqdm\n",
    "\n",
    "### Custom Classes\n",
    "from core.hierarchicalCrossEntropyLoss import hierarchicalCrossEntropyLoss as h_loss\n",
    "from core.trainer import train_model\n",
    "from utils import display_funcs as disp_funcs\n",
    "from utils import data_convert_funcs as convert_funcs\n",
    "\n",
    "# plt.ion()\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print('device:', device)\n",
    "\n",
    "import datetime\n",
    "now = datetime.datetime.now()\n",
    "save_name = 'hierarchicalSELoss'\n",
    "writer = SummaryWriter('./runs/{}'.format(save_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T18:03:11.756431Z",
     "start_time": "2020-02-19T18:03:11.748451Z"
    }
   },
   "outputs": [],
   "source": [
    "resolution = 224\n",
    "batch_size = 24\n",
    "num_epochs = 50\n",
    "\n",
    "data_dir = '../data/customDataSet'\n",
    "save_model_path = './trained/{}'.format(save_name)\n",
    "os.makedirs(save_model_path, exist_ok=True)\n",
    "\n",
    "# model_type = 'ResNet50'\n",
    "model_type = 'MobileNet_v2'\n",
    "purpose = 'Regression'\n",
    "# loss_type = 'MSE'\n",
    "purpose = 'Classification'\n",
    "# loss_type = 'CrossEntropy'\n",
    "loss_type = 'HierarchicalCrossEntropy'\n",
    "opt_type = 'Adam'\n",
    "# use_sample_weights = False\n",
    "use_sample_weights = True\n",
    "# use_scheduler = True\n",
    "use_scheduler = False\n",
    "# use_finetuning = True\n",
    "use_finetuning = True\n",
    "\n",
    "hierarchy_dict = {'0': 'Normal Multiclass Classification',\n",
    "                  '1': {'0': [1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
    "                        '1': [0, 0, 0, 0, 1, 1, 1, 1, 1]},\n",
    "                  '2': {'0': [1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
    "                        '1': [0, 0, 1, 1, 0, 0, 0, 0, 0],\n",
    "                        '2': [0, 0, 0, 0, 1, 1, 1, 0, 0],\n",
    "                        '3': [0, 0, 0, 0, 0, 0, 0, 1, 1]}\n",
    "                  }\n",
    "\n",
    "hierarchy_label_spilitters = []\n",
    "hierarchy_label_spilitters.append(convert_funcs.convertHierarchyDict2labelSplitters(hierarchy_dict['1']))\n",
    "hierarchy_label_spilitters.append(convert_funcs.convertHierarchyDict2labelSplitters(hierarchy_dict['2']))\n",
    "\n",
    "coefficient = [0.50, 0.10, 0.40] \n",
    "    \n",
    "# reserve\n",
    "class_weights = []\n",
    "\n",
    "class_names = None\n",
    "class_num = None\n",
    "losses = {'train':[], 'val':[]}\n",
    "accs = {'train':[], 'val':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T18:03:11.890074Z",
     "start_time": "2020-02-19T18:03:11.885088Z"
    }
   },
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.RandomCrop(resolution),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "#         transforms.ColorJitter(brightness=0.2, contrast=0.1, saturation=0, hue=0.05),\n",
    "#         transforms.RandomAffine(degrees=5, translate=(0,0), scale=(0.8, 1.2)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]), # For Imagenet Pretrained model\n",
    "#         transforms.RandomErasing(),\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(resolution),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # For Imagenet Pretrained model\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(resolution),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # For Imagenet Pretrained model\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T18:03:12.046679Z",
     "start_time": "2020-02-19T18:03:12.019727Z"
    }
   },
   "outputs": [],
   "source": [
    "labels_list = {}\n",
    "\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                     transform=data_transforms[x])\n",
    "                  for x in ['train', 'val', 'test']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size,\n",
    "                                              shuffle=True, num_workers=4)\n",
    "               for x in ['train', 'val', 'test']}\n",
    "\n",
    "dataset_size = {x: len(image_datasets[x]) for x in ['train', 'val', 'test']}\n",
    "class_names = image_datasets['train'].classes\n",
    "class_num = len(class_names)\n",
    "\n",
    "for x in ['train']:#, 'val']:\n",
    "    labels_list[x] = disp_funcs.show_data_histogram('{}/{}'.format(data_dir, x), '{} data'.format(x), show=True) \n",
    "    print(f'training data num is {len(labels_list[\"train\"])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T18:03:12.322959Z",
     "start_time": "2020-02-19T18:03:12.173324Z"
    }
   },
   "outputs": [],
   "source": [
    "num_classes = class_num if purpose == 'Classification' else 1\n",
    "if model_type == 'ResNet50':\n",
    "    model = models.resnet50(pretrained=True if use_finetuning == True else False)\n",
    "    model.fc = nn.Linear(in_features=2048, out_features= num_classes)\n",
    "elif model_type == 'ResNet152':\n",
    "    model = models.resnet152(pretrained=True if use_finetuning == True else False)\n",
    "    model.fc = nn.Linear(in_features=2048, out_features= num_classes)\n",
    "elif model_type == 'MobileNet_v2':\n",
    "    model = model = torch.hub.load('pytorch/vision:v0.5.0', 'mobilenet_v2', pretrained=True)\n",
    "    model.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(model.last_channel, num_classes),\n",
    "        )\n",
    "\n",
    "model.train()\n",
    "print('Chose {}'.format(model_type), 'Network setting is completed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T18:03:12.348855Z",
     "start_time": "2020-02-19T18:03:12.341876Z"
    }
   },
   "outputs": [],
   "source": [
    "if use_sample_weights == True:\n",
    "    sample_weights = compute_class_weight(class_weight='balanced', \n",
    "                                          classes=np.unique(labels_list['train']),\n",
    "                                          y=labels_list['train'])\n",
    "    sample_weights = torch.FloatTensor(sample_weights).to(device)\n",
    "    print(sample_weights)\n",
    "    if loss_type == 'HierarchicalCrossEntropy':\n",
    "        sample_weights = [sample_weights]\n",
    "        for i in range(len(coefficient)-1):\n",
    "            temp_classes = convert_funcs.convertClass2HierarchicalClass(labels_list['train'], hierarchy_label_spilitters[i])\n",
    "            temp_weights = compute_class_weight(class_weight='balanced', \n",
    "                                                classes=np.unique(temp_classes),\n",
    "                                                y=temp_classes)\n",
    "            temp_weights = convert_funcs.convertClassWeights2HierarchicalClassWeights(temp_weights, hierarchy_label_spilitters[i])\n",
    "            temp_weights = torch.FloatTensor(temp_weights).to(device)\n",
    "            sample_weights.append(temp_weights)\n",
    "            \n",
    "if loss_type == 'CrossEntropy':\n",
    "    criterion = torch.nn.CrossEntropyLoss(weight= None if use_sample_weights != True else sample_weights)\n",
    "elif loss_type == 'HierarchicalCrossEntropy':\n",
    "    criterion = h_loss(coefficient, hierarchy_dict, \n",
    "                       weight= None if use_sample_weights != True else sample_weights, device=device)\n",
    "elif loss_type == 'MSE':\n",
    "    criterion = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T18:03:16.649234Z",
     "start_time": "2020-02-19T18:03:16.644248Z"
    }
   },
   "outputs": [],
   "source": [
    "if opt_type == 'SGD':\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)        \n",
    "elif opt_type == 'Adam':\n",
    "    optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T18:03:17.008470Z",
     "start_time": "2020-02-19T18:03:17.004448Z"
    }
   },
   "outputs": [],
   "source": [
    "if use_scheduler == True:\n",
    "    scheduler = lr_scheduler.StepLR(optimizer, step_size=2.4, gamma=0.97)\n",
    "else:\n",
    "    scheduler = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T18:05:53.872393Z",
     "start_time": "2020-02-19T18:03:18.941294Z"
    }
   },
   "outputs": [],
   "source": [
    "model = train_model(model, dataloaders, \n",
    "                    purpose, criterion, optimizer, scheduler, \n",
    "                    num_epochs, losses, accs, \n",
    "                    save_model_path, device, writer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results (Run belows again after training finished)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-01T01:09:01.552187Z",
     "start_time": "2020-02-01T01:08:52.872435Z"
    }
   },
   "outputs": [],
   "source": [
    "from utils import analyze_result_funcs as ar\n",
    "\n",
    "analyzer = ar.show_results(class_num=class_num, device=device, model=model, \n",
    "                           trained_model_name=save_name+'best_model.pth')\n",
    "analyzer.calc_confusion_matrix(dataset=image_datasets['test'], purpose=purpose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-01T01:09:12.421938Z",
     "start_time": "2020-02-01T01:09:04.425358Z"
    }
   },
   "outputs": [],
   "source": [
    "analyzer.calc_classification_report(dataset=image_datasets['test'], purpose =purpose, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-01T01:09:01.552187Z",
     "start_time": "2020-02-01T01:08:52.872435Z"
    }
   },
   "outputs": [],
   "source": [
    "from utils import analyze_result_funcs as ar\n",
    "# import importlib\n",
    "# importlib.reload(ar)\n",
    "\n",
    "analyzer = ar.show_results(class_num=class_num, device=device, model=model, \n",
    "                           trained_model_name=save_name+'best_model.pth')\n",
    "analyzer.calc_confusion_matrix(dataset=image_datasets['val'], purpose=purpose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-01T01:09:12.421938Z",
     "start_time": "2020-02-01T01:09:04.425358Z"
    }
   },
   "outputs": [],
   "source": [
    "analyzer.calc_classification_report(dataset=image_datasets['val'], purpose =purpose, batch_size=8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "255.594px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
